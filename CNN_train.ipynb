{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import matplotlib.image as mpimg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "# load the data\n",
    "data_file = open('cifar_10_tf_train_test.pkl', 'rb')\n",
    "train_data, train_label, test_data, test_label = pickle.load(data_file, encoding='latin1')\n",
    "print(train_data.shape)\n",
    "data_file.close()\n",
    "train_label = np.array(train_label)\n",
    "test_label = np.array(test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "hm_train_data, dim1, dim2, hm_channel = train_data.shape\n",
    "hm_test_data, _, _, _ = test_data.shape\n",
    "hm_class = 10\n",
    "\n",
    "batch_size = 100\n",
    "max_epoch = 50\n",
    "eval_interval = 300\n",
    "\n",
    "# pre-process the data, cast to float32, scaling, and normalize\n",
    "train_data = train_data.astype(np.float32) / 255.\n",
    "train_label = train_label.astype(np.int64)\n",
    "test_data = test_data.astype(np.float32) / 255.\n",
    "test_label = test_label.astype(np.int64)\n",
    "\n",
    "train_data -= np.mean(train_data, axis=(1, 2, 3), keepdims=True)\n",
    "test_data -= np.mean(test_data, axis=(1, 2, 3), keepdims=True)\n",
    "test_acc = np.zeros((0, 1))\n",
    "train_acc = np.zeros((0, 1))\n",
    "loss = np.zeros((0, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.placeholder(shape=[None, 32, 32, 3], dtype=tf.float32)\n",
    "y = tf.placeholder(shape=[None], dtype=tf.int64)\n",
    "keep_prob = tf.placeholder(dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weight_init(name, shape):\n",
    "    initial = tf.truncated_normal(shape, stddev=0.01) / 100.\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "\n",
    "def bias_init(name, shape):\n",
    "    initial = tf.constant(0.001, shape=shape)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "\n",
    "def conv2d(x, w):\n",
    "    return tf.nn.conv2d(x, w, strides=[1, 1, 1, 1], padding='VALID')\n",
    "\n",
    "\n",
    "def max_pool_2x2(x):\n",
    "    return tf.nn.max_pool(x, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='VALID')\n",
    "\n",
    "\n",
    "def avg_pool_2x2(x):\n",
    "    return tf.nn.avg_pool(x, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='VALID')\n",
    "\n",
    "\n",
    "def drop_out(h, portion):\n",
    "    return tf.nn.dropout(h, portion)\n",
    "\n",
    "def predict(h_conv3, b_fc1, w_fc1, portion):\n",
    "    h_conv3_drop = drop_out(h_conv3, portion)\n",
    "    fc1 = tf.reshape(h_conv3_drop, [-1, 3 * 3 * 64])\n",
    "    y_out = tf.matmul(fc1, w_fc1) + b_fc1\n",
    "    return tf.argmax(y_out,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forward propagation, 1st stage\n",
    "w_conv1 = weight_init('weight_conv1', [5, 5, 3, 32])\n",
    "b_conv1 = bias_init('bias_conv1', [28, 28, 32])\n",
    "image = tf.reshape(x, [-1, 32, 32, 3])\n",
    "\n",
    "h_conv1 = tf.nn.relu(conv2d(image, w_conv1) + b_conv1)\n",
    "h_pool1 = avg_pool_2x2(h_conv1)\n",
    "\n",
    "# 2nd stage\n",
    "w_conv2 = weight_init('weight_conv2', [5, 5, 32, 32])\n",
    "b_conv2 = bias_init('bias_conv2', [10, 10, 32])\n",
    "\n",
    "h_conv2 = tf.nn.relu(conv2d(h_pool1, w_conv2) + b_conv2)\n",
    "h_pool2 = max_pool_2x2(h_conv2)\n",
    "\n",
    "# 3rd stage\n",
    "w_conv3 = weight_init('weight_conv3', [3, 3, 32, 64])\n",
    "b_conv3 = bias_init('bias_conv3', [3, 3, 64])\n",
    "\n",
    "h_conv3 = tf.nn.relu(conv2d(h_pool2, w_conv3) + b_conv3)\n",
    "\n",
    "#h_pool3 = max_pool_2x2(h_conv3)\n",
    "\n",
    "# drop out 50% during training\n",
    "\n",
    "h_conv3_drop = drop_out(h_conv3, keep_prob)\n",
    "\n",
    "\n",
    "\n",
    "# fully connected layer\n",
    "fc1 = tf.reshape(h_conv3_drop, [-1, 3 * 3 * 64])\n",
    "w_fc1 = weight_init('weight_fc1', [3 * 3 * 64, hm_class])\n",
    "b_fc1 = bias_init('bias_fc1', [hm_class])\n",
    "\n",
    "# output layer\n",
    "y_out = tf.matmul(fc1, w_fc1) + b_fc1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_entropy = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(logits=y_out, labels=y))\n",
    "train_step = tf.train.AdamOptimizer(learning_rate=0.001).minimize(cross_entropy)\n",
    "#train_step = tf.train.RMSPropOptimizer(learning_rate=0.002, decay=0.6).minimize(cross_entropy)\n",
    "predict_op = predict(h_conv3, b_fc1, w_fc1, 1)\n",
    "correct_prediction = tf.equal(tf.argmax(y_out, 1), y)\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "# Save the model\n",
    "tf.get_collection('validation_nodes')\n",
    "\n",
    "# Add opts to the collection\n",
    "tf.add_to_collection('validation_nodes', x)\n",
    "tf.add_to_collection('validation_nodes', y)\n",
    "tf.add_to_collection('validation_nodes', predict_op)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0 step: 0, training accuracy: 0.06, testing accuracy: 0.1026, loss: 2.30259\n",
      "epoch: 0 step: 300, training accuracy: 0.37, testing accuracy: 0.3412, loss: 1.73188\n",
      "Epoch 0 training done, runtime 0:00:06.492011\n",
      "epoch: 1 step: 0, training accuracy: 0.46, testing accuracy: 0.444, loss: 1.65926\n",
      "epoch: 1 step: 300, training accuracy: 0.47, testing accuracy: 0.498, loss: 1.3384\n",
      "Epoch 1 training done, runtime 0:00:04.686205\n",
      "epoch: 2 step: 0, training accuracy: 0.5, testing accuracy: 0.529, loss: 1.46833\n",
      "epoch: 2 step: 300, training accuracy: 0.6, testing accuracy: 0.5498, loss: 1.05433\n",
      "Epoch 2 training done, runtime 0:00:04.614797\n",
      "epoch: 3 step: 0, training accuracy: 0.53, testing accuracy: 0.565, loss: 1.18474\n",
      "epoch: 3 step: 300, training accuracy: 0.54, testing accuracy: 0.5808, loss: 1.24955\n",
      "Epoch 3 training done, runtime 0:00:04.679670\n",
      "epoch: 4 step: 0, training accuracy: 0.6, testing accuracy: 0.5964, loss: 1.20846\n",
      "epoch: 4 step: 300, training accuracy: 0.57, testing accuracy: 0.6044, loss: 1.08492\n",
      "Epoch 4 training done, runtime 0:00:04.730905\n",
      "epoch: 5 step: 0, training accuracy: 0.66, testing accuracy: 0.6082, loss: 0.981287\n",
      "epoch: 5 step: 300, training accuracy: 0.6, testing accuracy: 0.6184, loss: 1.05597\n",
      "Epoch 5 training done, runtime 0:00:04.684852\n",
      "epoch: 6 step: 0, training accuracy: 0.64, testing accuracy: 0.6292, loss: 0.964421\n",
      "epoch: 6 step: 300, training accuracy: 0.64, testing accuracy: 0.6378, loss: 0.913583\n",
      "Epoch 6 training done, runtime 0:00:04.679247\n",
      "epoch: 7 step: 0, training accuracy: 0.58, testing accuracy: 0.637, loss: 1.07649\n",
      "epoch: 7 step: 300, training accuracy: 0.76, testing accuracy: 0.6474, loss: 0.864172\n",
      "Epoch 7 training done, runtime 0:00:04.718528\n",
      "epoch: 8 step: 0, training accuracy: 0.62, testing accuracy: 0.6504, loss: 0.896389\n",
      "epoch: 8 step: 300, training accuracy: 0.69, testing accuracy: 0.6538, loss: 0.961845\n",
      "Epoch 8 training done, runtime 0:00:04.737392\n",
      "epoch: 9 step: 0, training accuracy: 0.63, testing accuracy: 0.6612, loss: 0.936962\n",
      "epoch: 9 step: 300, training accuracy: 0.64, testing accuracy: 0.6778, loss: 0.995259\n",
      "Epoch 9 training done, runtime 0:00:04.658596\n",
      "epoch: 10 step: 0, training accuracy: 0.63, testing accuracy: 0.6566, loss: 0.872142\n",
      "epoch: 10 step: 300, training accuracy: 0.73, testing accuracy: 0.665, loss: 0.797505\n",
      "Epoch 10 training done, runtime 0:00:04.728452\n",
      "epoch: 11 step: 0, training accuracy: 0.78, testing accuracy: 0.676, loss: 0.669889\n",
      "epoch: 11 step: 300, training accuracy: 0.76, testing accuracy: 0.687, loss: 0.782133\n",
      "Epoch 11 training done, runtime 0:00:04.634587\n",
      "epoch: 12 step: 0, training accuracy: 0.74, testing accuracy: 0.6846, loss: 0.739518\n",
      "epoch: 12 step: 300, training accuracy: 0.7, testing accuracy: 0.679, loss: 0.815033\n",
      "Epoch 12 training done, runtime 0:00:04.631991\n",
      "epoch: 13 step: 0, training accuracy: 0.81, testing accuracy: 0.6884, loss: 0.637067\n",
      "epoch: 13 step: 300, training accuracy: 0.78, testing accuracy: 0.6798, loss: 0.722018\n",
      "Epoch 13 training done, runtime 0:00:04.760889\n",
      "epoch: 14 step: 0, training accuracy: 0.76, testing accuracy: 0.6832, loss: 0.702887\n",
      "epoch: 14 step: 300, training accuracy: 0.69, testing accuracy: 0.6856, loss: 0.834142\n",
      "Epoch 14 training done, runtime 0:00:04.702603\n",
      "epoch: 15 step: 0, training accuracy: 0.76, testing accuracy: 0.687, loss: 0.646947\n",
      "epoch: 15 step: 300, training accuracy: 0.71, testing accuracy: 0.6906, loss: 0.779487\n",
      "Epoch 15 training done, runtime 0:00:04.680127\n",
      "epoch: 16 step: 0, training accuracy: 0.8, testing accuracy: 0.7046, loss: 0.553299\n",
      "epoch: 16 step: 300, training accuracy: 0.78, testing accuracy: 0.6982, loss: 0.667219\n",
      "Epoch 16 training done, runtime 0:00:04.632995\n",
      "epoch: 17 step: 0, training accuracy: 0.83, testing accuracy: 0.6978, loss: 0.457657\n",
      "epoch: 17 step: 300, training accuracy: 0.77, testing accuracy: 0.6988, loss: 0.598268\n",
      "Epoch 17 training done, runtime 0:00:04.728050\n",
      "epoch: 18 step: 0, training accuracy: 0.77, testing accuracy: 0.6962, loss: 0.732451\n",
      "epoch: 18 step: 300, training accuracy: 0.77, testing accuracy: 0.7026, loss: 0.689237\n",
      "Epoch 18 training done, runtime 0:00:04.620351\n",
      "epoch: 19 step: 0, training accuracy: 0.79, testing accuracy: 0.6994, loss: 0.555648\n",
      "epoch: 19 step: 300, training accuracy: 0.79, testing accuracy: 0.7024, loss: 0.594677\n",
      "Epoch 19 training done, runtime 0:00:04.628836\n",
      "epoch: 20 step: 0, training accuracy: 0.84, testing accuracy: 0.6986, loss: 0.459203\n",
      "epoch: 20 step: 300, training accuracy: 0.76, testing accuracy: 0.7066, loss: 0.619194\n",
      "Epoch 20 training done, runtime 0:00:04.649822\n",
      "epoch: 21 step: 0, training accuracy: 0.76, testing accuracy: 0.7116, loss: 0.532029\n",
      "epoch: 21 step: 300, training accuracy: 0.78, testing accuracy: 0.706, loss: 0.581993\n",
      "Epoch 21 training done, runtime 0:00:04.630067\n",
      "epoch: 22 step: 0, training accuracy: 0.85, testing accuracy: 0.7056, loss: 0.501712\n",
      "epoch: 22 step: 300, training accuracy: 0.76, testing accuracy: 0.7032, loss: 0.617501\n",
      "Epoch 22 training done, runtime 0:00:04.632723\n",
      "epoch: 23 step: 0, training accuracy: 0.76, testing accuracy: 0.7064, loss: 0.627527\n",
      "epoch: 23 step: 300, training accuracy: 0.78, testing accuracy: 0.705, loss: 0.522574\n",
      "Epoch 23 training done, runtime 0:00:04.683665\n",
      "epoch: 24 step: 0, training accuracy: 0.79, testing accuracy: 0.7022, loss: 0.597549\n",
      "epoch: 24 step: 300, training accuracy: 0.79, testing accuracy: 0.7016, loss: 0.531348\n",
      "Epoch 24 training done, runtime 0:00:04.650807\n",
      "epoch: 25 step: 0, training accuracy: 0.83, testing accuracy: 0.7124, loss: 0.525856\n",
      "epoch: 25 step: 300, training accuracy: 0.78, testing accuracy: 0.7008, loss: 0.559933\n",
      "Epoch 25 training done, runtime 0:00:04.650301\n",
      "epoch: 26 step: 0, training accuracy: 0.77, testing accuracy: 0.7076, loss: 0.550499\n",
      "epoch: 26 step: 300, training accuracy: 0.83, testing accuracy: 0.7034, loss: 0.440982\n",
      "Epoch 26 training done, runtime 0:00:04.695295\n",
      "epoch: 27 step: 0, training accuracy: 0.79, testing accuracy: 0.7024, loss: 0.5352\n",
      "epoch: 27 step: 300, training accuracy: 0.81, testing accuracy: 0.7116, loss: 0.544743\n",
      "Epoch 27 training done, runtime 0:00:04.630502\n",
      "epoch: 28 step: 0, training accuracy: 0.85, testing accuracy: 0.7024, loss: 0.42657\n",
      "epoch: 28 step: 300, training accuracy: 0.87, testing accuracy: 0.6998, loss: 0.445761\n",
      "Epoch 28 training done, runtime 0:00:04.634495\n",
      "epoch: 29 step: 0, training accuracy: 0.82, testing accuracy: 0.7054, loss: 0.451781\n",
      "epoch: 29 step: 300, training accuracy: 0.86, testing accuracy: 0.708, loss: 0.409882\n",
      "Epoch 29 training done, runtime 0:00:04.694946\n",
      "epoch: 30 step: 0, training accuracy: 0.92, testing accuracy: 0.7094, loss: 0.255379\n",
      "epoch: 30 step: 300, training accuracy: 0.85, testing accuracy: 0.7094, loss: 0.438089\n",
      "Epoch 30 training done, runtime 0:00:04.649373\n",
      "epoch: 31 step: 0, training accuracy: 0.87, testing accuracy: 0.7044, loss: 0.373817\n",
      "epoch: 31 step: 300, training accuracy: 0.73, testing accuracy: 0.7092, loss: 0.697879\n",
      "Epoch 31 training done, runtime 0:00:04.630560\n",
      "epoch: 32 step: 0, training accuracy: 0.86, testing accuracy: 0.7108, loss: 0.400384\n",
      "epoch: 32 step: 300, training accuracy: 0.9, testing accuracy: 0.7066, loss: 0.338132\n",
      "Epoch 32 training done, runtime 0:00:04.667044\n",
      "epoch: 33 step: 0, training accuracy: 0.91, testing accuracy: 0.7064, loss: 0.292873\n",
      "epoch: 33 step: 300, training accuracy: 0.83, testing accuracy: 0.7078, loss: 0.40168\n",
      "Epoch 33 training done, runtime 0:00:04.664823\n",
      "epoch: 34 step: 0, training accuracy: 0.9, testing accuracy: 0.7152, loss: 0.31904\n",
      "epoch: 34 step: 300, training accuracy: 0.82, testing accuracy: 0.7076, loss: 0.406436\n",
      "Epoch 34 training done, runtime 0:00:04.615243\n",
      "epoch: 35 step: 0, training accuracy: 0.87, testing accuracy: 0.7042, loss: 0.40681\n",
      "epoch: 35 step: 300, training accuracy: 0.87, testing accuracy: 0.7054, loss: 0.414159\n",
      "Epoch 35 training done, runtime 0:00:04.730354\n",
      "epoch: 36 step: 0, training accuracy: 0.87, testing accuracy: 0.7162, loss: 0.440656\n",
      "epoch: 36 step: 300, training accuracy: 0.86, testing accuracy: 0.7012, loss: 0.376098\n",
      "Epoch 36 training done, runtime 0:00:04.699480\n",
      "epoch: 37 step: 0, training accuracy: 0.81, testing accuracy: 0.7096, loss: 0.473083\n",
      "epoch: 37 step: 300, training accuracy: 0.93, testing accuracy: 0.7144, loss: 0.298612\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37 training done, runtime 0:00:04.708333\n",
      "epoch: 38 step: 0, training accuracy: 0.86, testing accuracy: 0.7014, loss: 0.383965\n",
      "epoch: 38 step: 300, training accuracy: 0.86, testing accuracy: 0.7094, loss: 0.362346\n",
      "Epoch 38 training done, runtime 0:00:04.717040\n",
      "epoch: 39 step: 0, training accuracy: 0.91, testing accuracy: 0.7098, loss: 0.231378\n",
      "epoch: 39 step: 300, training accuracy: 0.92, testing accuracy: 0.7108, loss: 0.311639\n",
      "Epoch 39 training done, runtime 0:00:04.666042\n",
      "epoch: 40 step: 0, training accuracy: 0.92, testing accuracy: 0.705, loss: 0.233637\n",
      "epoch: 40 step: 300, training accuracy: 0.78, testing accuracy: 0.7082, loss: 0.501941\n",
      "Epoch 40 training done, runtime 0:00:04.651846\n",
      "epoch: 41 step: 0, training accuracy: 0.85, testing accuracy: 0.7102, loss: 0.37816\n",
      "epoch: 41 step: 300, training accuracy: 0.82, testing accuracy: 0.6992, loss: 0.463761\n",
      "Epoch 41 training done, runtime 0:00:04.630563\n",
      "epoch: 42 step: 0, training accuracy: 0.86, testing accuracy: 0.7118, loss: 0.360175\n",
      "epoch: 42 step: 300, training accuracy: 0.89, testing accuracy: 0.7016, loss: 0.314718\n",
      "Epoch 42 training done, runtime 0:00:04.680730\n",
      "epoch: 43 step: 0, training accuracy: 0.9, testing accuracy: 0.7076, loss: 0.32468\n",
      "epoch: 43 step: 300, training accuracy: 0.89, testing accuracy: 0.7088, loss: 0.288021\n",
      "Epoch 43 training done, runtime 0:00:04.665386\n",
      "epoch: 44 step: 0, training accuracy: 0.91, testing accuracy: 0.7036, loss: 0.335158\n",
      "epoch: 44 step: 300, training accuracy: 0.82, testing accuracy: 0.7004, loss: 0.403614\n",
      "Epoch 44 training done, runtime 0:00:04.634853\n",
      "epoch: 45 step: 0, training accuracy: 0.9, testing accuracy: 0.7118, loss: 0.2845\n",
      "epoch: 45 step: 300, training accuracy: 0.91, testing accuracy: 0.7086, loss: 0.292441\n",
      "Epoch 45 training done, runtime 0:00:04.680203\n",
      "epoch: 46 step: 0, training accuracy: 0.87, testing accuracy: 0.7086, loss: 0.422382\n",
      "epoch: 46 step: 300, training accuracy: 0.9, testing accuracy: 0.7054, loss: 0.288665\n",
      "Epoch 46 training done, runtime 0:00:04.682058\n",
      "epoch: 47 step: 0, training accuracy: 0.91, testing accuracy: 0.6962, loss: 0.265828\n",
      "epoch: 47 step: 300, training accuracy: 0.9, testing accuracy: 0.7064, loss: 0.300067\n",
      "Epoch 47 training done, runtime 0:00:04.650716\n",
      "epoch: 48 step: 0, training accuracy: 0.91, testing accuracy: 0.7054, loss: 0.260682\n",
      "epoch: 48 step: 300, training accuracy: 0.86, testing accuracy: 0.706, loss: 0.365589\n",
      "Epoch 48 training done, runtime 0:00:04.654912\n",
      "epoch: 49 step: 0, training accuracy: 0.91, testing accuracy: 0.703, loss: 0.295545\n",
      "epoch: 49 step: 300, training accuracy: 0.97, testing accuracy: 0.7068, loss: 0.164603\n",
      "Epoch 49 training done, runtime 0:00:04.646087\n",
      "Training finished! Final training accuracy: 0.7742, testing accuracy: 0.7046\n"
     ]
    }
   ],
   "source": [
    "# start training and eval accuracy\n",
    "# with tf.Session() as sess:\n",
    "saver = tf.train.Saver()\n",
    "sess = tf.Session()\n",
    "#with tf.Session() as sess:\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "for epoch in np.arange(max_epoch):\n",
    "    start = datetime.datetime.now()\n",
    "    re_order = np.random.permutation(hm_train_data)\n",
    "    \n",
    "\n",
    "    for i in np.arange(int(hm_train_data / batch_size)):\n",
    "        batch_x = train_data[re_order[i * batch_size:(i + 1) * batch_size], :, :, :]\n",
    "        batch_y = train_label[re_order[i * batch_size:(i + 1) * batch_size]]\n",
    "\n",
    "        # evaluate the training performance\n",
    "        if i % eval_interval == 0:\n",
    "            ce = sess.run(cross_entropy, feed_dict={x: batch_x, y:batch_y, keep_prob:1})\n",
    "            train_accuracy = sess.run(accuracy, feed_dict={x: batch_x, y:batch_y, keep_prob:1})\n",
    "            test_accuracy = sess.run(accuracy, feed_dict={x: test_data, y: test_label, keep_prob:1})\n",
    "            train_acc = np.vstack((train_acc, train_accuracy))\n",
    "            test_acc = np.vstack((test_acc, test_accuracy))\n",
    "            loss = np.vstack((loss, ce))\n",
    "            print(\"epoch: %d step: %d, training accuracy: %g, testing accuracy: %g, loss: %g\" %\n",
    "                            (epoch, i, train_accuracy, test_accuracy, ce))\n",
    "\n",
    "        sess.run(train_step, feed_dict={x: batch_x, y: batch_y, keep_prob:0.5})\n",
    "\n",
    "    dur = datetime.datetime.now() - start\n",
    "    print('Epoch', epoch, 'training done, runtime', dur)\n",
    "\n",
    "#train_accuracy = sess.run(accuracy, feed_dict={x: train_data, y: train_label, keep_prob:1})\n",
    "test_accuracy = sess.run(accuracy, feed_dict={x: test_data, y: test_label, keep_prob:1})\n",
    "print(\"Training finished! Final training accuracy: %g, testing accuracy: %g\" %\n",
    "                (np.mean(train_acc[-int(hm_train_data/batch_size):, :]), test_accuracy))\n",
    "#train_acc = np.vstack((train_acc, train_accuracy))\n",
    "test_acc = np.vstack((test_acc, test_accuracy))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = saver.save(sess, './my_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
